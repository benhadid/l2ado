<h1 id="objectifs">Objectifs</h1>

<ul>
  <li>
    <p>Découvrir comment les schémas d’accès à la mémoire déterminent les taux de succès de cache.</p>
  </li>
  <li>
    <p>Déterminer quels schémas d’accès à la mémoire produisent de BONS taux de succès.</p>
  </li>
  <li>
    <p>Être en mesure d’optimiser le code pour produire de bons taux de succès de cache.</p>
  </li>
</ul>

<h1 id="outils-de--visualisation-de-cache--dans-mars">Outils de « Visualisation de Cache » dans MARS</h1>

<p>Cet exercice utilise des outils de visualisation de cache dans MARS afin de vous familiariser avec le comportement du cache et la terminologie des mesures de performance. Ce n’est pas un exercice réel, mais plutôt une explication sur la façon d’utiliser MARS comme outil de visualisation du cache !</p>

<p>Commencez par télécharger le fichier de démarrage et décompressez son contenu dans le répertoire de votre choix. Ensuite, ouvrez le fichier <code class="language-plaintext highlighter-rouge">cache.s</code> dans MARS et examinez son contenu pour avoir une idée approximative de ce que fait le programme avant de procéder avec la suite.</p>

<ul>
  <li>
    <p>La partie la plus importante à comprendre dans le programme est la section intitulée “PSEUDOCODE” en haut du fichier.  Fondamentalement, nous allons simplement remettre à zéro certains éléments d’un tableau (option 0) ou les incrémenterez (option 1).</p>
  </li>
  <li>
    <p><strong>Quels</strong> éléments sont accédés dans le tableau est déterminé par le pas <code class="language-plaintext highlighter-rouge">step size</code> ($a1). Et le nombre de fois que nous faisons cela est contrôlé par le paramètre <code class="language-plaintext highlighter-rouge">repcount</code> ($a2). <strong>Ces deux paramètres affecteront directement les taux de succès et d’échec dans le cache</strong>. L’option ($a3) changera également certaines choses, tout comme les paramètres propres du cache.</p>
  </li>
</ul>

<p>Pour chacun des scénarios de l’exercice 1 ci-dessous, vous répéterez les étapes suivantes :</p>

<ol>
  <li>
    <p>Définir dans <code class="language-plaintext highlighter-rouge">caches.s</code> les paramètres de programme appropriés comme indiqué au début de chaque scénario (en modifiant les valeurs immédiates des instructions <code class="language-plaintext highlighter-rouge">li</code> signalés dans la fonction <code class="language-plaintext highlighter-rouge">main</code>)</p>
  </li>
  <li>
    <p>Exécuter « <strong>Tools | Data Cache Simulator</strong> ».</p>
  </li>
  <li>
    <p>Définir les paramètres de cache appropriés comme indiqué au début de chaque scénario.</p>
  </li>
  <li>
    <p>Activer le journal d’exécution (Runtime Log), puis cliquez sur “Connect to MIPS”.</p>
  </li>
  <li>
    <p>Exécuter « <strong>Tools | Memory Reference Visualization</strong> » et cliquez sur “Connect to MIPS”.</p>
  </li>
  <li>
    <p>Au fur et à mesure que vous avancez dans le code dans MARS, tout accès au segment de données de la mémoire (chargement ou sauvegarde) sera visualisé (les accès à la mémoire d’instructions ne sont pas affichées).</p>
  </li>
</ol>

<p>Le « <strong>Data Cache Simulator</strong> » affichera l’état de votre cache de données et le « <strong>Memory Reference Visualization</strong> » montrera quelles parties de la mémoire sont accédées et combien de fois. Rappelons que ces outils fonctionnent indépendamment de votre code, donc si vous effectuez un « reset » sur le code <code class="language-plaintext highlighter-rouge">cache.s</code> (ou autre), vous devez également réinitialiser le contenu du cache et de la mémoire !</p>

<p><strong>REMARQUE</strong> : Si vous exécutez le code en un coup (au lieu d’une exécution pas-à-pas), vous obtiendrez l’état final du cache et le taux de succès. Afin de mieux voir quels « pas / itérations » affectent les taux de succès et d’échec dans le programme, insérez un « point d’arrêt » dans la <strong>boucle</strong> <code class="language-plaintext highlighter-rouge">wordLoop</code> juste avant ou après chaque accès à la mémoire.</p>

<h1 id="exercice-1--quelques-scénarios-daccès-à-la-mémoire">Exercice 1 : (Quelques scénarios d’accès à la mémoire)</h1>

<h2 id="tâches-à-réaliser-">Tâches à réaliser :</h2>

<p>Simulez les scénarios suivants et notez les taux finaux de succès de cache avec le programme <code class="language-plaintext highlighter-rouge">cache.s</code>. Essayez de déduire quel sera le taux de succès AVANT d’exécuter le code. Après avoir exécuté chaque simulation, assurez-vous de comprendre LE POURQUOI des résultats obtenus (cela pourrait finir comme une question dans l’examen)!</p>

<p>Voici quelques questions auxquelles vous devriez pouvoir répondre et qui vous aideront à mieux comprendre les problèmes posés dans les scénarios ci-dessous :</p>

<ul>
  <li>Quelle est la taille du bloc mémoire / ligne de cache ?</li>
  <li>Combien d’accès consécutifs (en tenant compte de la taille du pas) accèdent au même bloc ?</li>
  <li>Combien de données tiennent dans TOUT le cache ?</li>
  <li>À quelle distance en mémoire se trouvent les blocs qui correspondent à la même ligne de cache (et pourraient donc créer des conflits) ?</li>
  <li>Quelle est l’associativité du cache ?</li>
  <li>À quel endroit du cache un bloc particulier en mémoire sera mappé ?</li>
  <li>Pour décider si un accès spécifique au cache est un échec ou un succès : a-t-on déjà accédé à cette donnée ? Si tel est le cas, est-elle toujours dans le cache ou non ?</li>
</ul>

<h3 id="scénario-1">Scénario 1</h3>

<p><strong>Paramètres du cache :</strong> (à définir dans la fenêtre « <strong>Data Cache Simulator</strong> »)</p>

<ul>
  <li><strong>Placement Policy (type du cache):</strong> Direct Mapping  (cache direct).</li>
  <li><strong>Block Replacement Policy (politique de remplacement de bloc):</strong> LRU.</li>
  <li><strong>Set size (nombre de blocs par ligne de cache) :</strong> 1. (MARS ne vous autorisera pas à changer cette valeur. Pourquoi?)</li>
  <li><strong>Number of blocks (nombre de blocs dans le cache):</strong> 4.</li>
  <li><strong>Cache block size (taille du bloc de cache):</strong> 2 (en mots).</li>
</ul>

<p><strong>Paramètres du programme :</strong> (à définir en initialisant les registres <strong>$a?</strong> dans <code class="language-plaintext highlighter-rouge">cache.s</code>)</p>

<ul>
  <li><strong>Array Size (taille du tableau) :</strong> 128 (octets).</li>
  <li><strong>Step Size (pas) :</strong> 8.</li>
  <li><strong>repcount (nombre de répétitions) :</strong> 4.</li>
  <li><strong>Option :</strong> 0.</li>
</ul>

<p><strong>Indication :</strong> : S’il vous est difficile de visualiser ce qui est mis dans le cache à chaque accès mémoire en examinant simplement le code, essayez avec du papier et un crayon ! Notez ce que serait la décomposition (Tag / Index / Offset) des adresses 32 bits et déterminez quelles adresses mémoire mappent vers quelle lignes dans le cache avec les bits d’Index.</p>

<ol>
  <li>
    <p>Quelle combinaison de paramètres produit le taux de succès que vous observez ? (Indice : votre réponse doit être de la forme : « Parce que [paramètre A] en octets est exactement égal à [paramètre B] en octets.»). <strong>Remarque :</strong> Rappelons que la taille du cache est définit implicitement par la « taille du bloc » et le « nombre de blocs » dans le cache.</p>
  </li>
  <li>
    <p>Quel est le taux de succès du cache si nous augmentons arbitrairement le paramètre <code class="language-plaintext highlighter-rouge">repcount</code> ? Pourquoi ?</p>
  </li>
  <li>
    <p>Comment pourrions-nous modifier un paramètre dans le programme pour augmenter notre taux de succès ? (Indice: votre réponse doit être de la forme: “Remplacez [paramètre] par [valeur]”). <strong>Remarque :</strong> Il n’est pas important si nous accédons aux mêmes éléments du tableau. Donnez simplement une modification des paramètres du programme qui augmenterait le taux de succès. Assurez-vous, cependant, que la valeur proposée soit valide.</p>
  </li>
</ol>

<h3 id="scénario-2">Scénario 2</h3>

<p><strong>Paramètres du cache :</strong></p>

<ul>
  <li><strong>Placement Policy (type du cache):</strong> N-way Set Associative (cache N-associatif).</li>
  <li><strong>Block Replacement Policy (politique de remplacement de bloc):</strong> LRU.</li>
  <li><strong>Set size (nombre de blocs par ligne de cache) :</strong> 4.</li>
  <li><strong>Number of blocks (nombre de blocs dans le cache):</strong> 16.</li>
  <li><strong>Cache block size (taille du bloc de cache):</strong> 4 (en mots)</li>
</ul>

<p><strong>Paramètres du programme :</strong></p>

<ul>
  <li><strong>Array Size (taille du tableau) :</strong> 256 (octets)</li>
  <li><strong>Step Size (pas) :</strong> 2</li>
  <li><strong>repcount (nombre de répétitions) :</strong> 1</li>
  <li><strong>Option :</strong> 1</li>
</ul>

<ol>
  <li>
    <p>Combien d’accès mémoire y a-t-il par itération de la boucle interne ? (pas celle impliquant <code class="language-plaintext highlighter-rouge">repcount</code>) ? Ce n’est pas 1 !</p>
  </li>
  <li>
    <p>Quel est le motif de répétition des succès / échecs ? POURQUOI ? (<strong>Indice :</strong> ils se répètent tous les 4 accès). Maintenant, donnez le taux de succès en termes de ce motif de répétition.</p>
  </li>
  <li>
    <p>Qu’arrive-t-il à notre taux de succès si le nombre de répétitions <code class="language-plaintext highlighter-rouge">repcount</code> passe à l’infini (c.-à-d. notre boucle devient infini) ? Pourquoi ?</p>
  </li>
</ol>

<p>Vous auriez dû remarquer que le taux de succès était assez élevé pour le scénario 2, et votre réponse à la question précédente devrait vous aider à comprendre pourquoi est-ce le cas. Si vous ne savez pas pourquoi, considérez la taille du tableau et comparez-la à la taille du cache. Maintenant, considérez ce qui suit :</p>

<p>Supposons que nous ayons un programme qui itère <code class="language-plaintext highlighter-rouge">repcount</code> fois sur un très grand tableau (c.-à-d. bien plus grand que la taille du cache). Pendant chaque itération, nous mappons une fonction différente aux éléments de notre tableau (par exemple, si <code class="language-plaintext highlighter-rouge">repcount = 1024</code>, nous mappons 1024 fonctions différentes sur chacun des éléments du tableau). Pour référence, dans le scénario 2, nous n’avions qu’une fonction d’incrémentation et une itération.</p>

<ol start="4">
  <li>En tenant compte de la description ci-dessus, comment pouvons-nous restructurer les accès au tableau <code class="language-plaintext highlighter-rouge">array</code> pour atteindre un taux de succès comme celui obtenu avant (en supposons que chaque élément du tableau est modifié indépendamment des autres, c.-à-d. qu’il n’est pas important si la répétition k est appliquée à l’élément <code class="language-plaintext highlighter-rouge">arr[i+1]</code> avant qu’elle ne soit appliquée à l’élément <code class="language-plaintext highlighter-rouge">arr[i]</code>, etc.) ?</li>
</ol>

<p><strong>Indication :</strong> Il ne serait pas judicieux de parcourir la totalité du tableau à chaque répétition car il est beaucoup plus volumineux que votre cache. Cela réduirait la quantité de localité temporelle exposée par votre programme et de ce fait impacterait négativement le taux de succès du cache.</p>

<p>L’idée est d’exposer plus de localité afin que nos caches puissent profiter de notre comportement prévisible. Donc, nous devrions essayer d’accéder à ________ du tableau à la fois et appliquer toutes les ________ à ces ________ avant de continuer avec un nouveau ________. Cela nous permettra de garder ________ du tableau bien au chaud dans le cache pendant toute la procédure et ne pas avoir à faire le tour plus tard ! (Les 1<sup>er</sup>, 3<sup>ème</sup> et 5<sup>ème</sup> espaces doivent être identiques. Ce n’est pas un terme de vocabulaire spécifique que vous devriez utiliser pour les remplir. C’est plutôt une idée que vous devriez avoir).</p>

<h1 id="exercice-2--ordre-des-boucles-et-multiplication-matricielle">Exercice 2 : (Ordre des boucles et multiplication matricielle)</h1>

<p>Pour rappel, les matrices sont des structures de données à deux dimensions dans lesquelles chaque élément de données est accessible via deux indices. Pour multiplier deux matrices, nous pouvons simplement utiliser trois boucles imbriquées. Par exemple, en supposant des matrices A, B et C de dimensions n-par-n et stockées dans des tableaux de colonnes à une dimension :</p>

<pre><code class="language-C">for (int i = 0; i &lt; n; i++)
    for (int j = 0; j &lt; n; j++)
        for (int k = 0; k &lt; n; k++)
            C[i+j*n] += A[i+k*n] * B[k+j*n];
</code></pre>

<p>Les opérations de multiplication matricielle sont au cœur de nombreux algorithmes d’algèbre linéaire, et une multiplication matricielle efficace est essentielle pour de nombreuses applications dans les sciences appliquées.</p>

<p>Dans le code ci-dessus, notez que les boucles sont ordonnées i, j, k. Si nous examinons la boucle la plus interne (celle qui incrémente k), on voit que elle…</p>

<ul>
  <li>accède le tableau B avec un pas de 1</li>
  <li>accède le tableau A avec un pas de n</li>
  <li>accède le tableau C avec un pas de 0 (ne dépend pas de k)</li>
</ul>

<p>Pour calculer <strong>correctement</strong> la multiplication matricielle, l’ordre des boucles n’a pas d’importance. <strong>MAIS</strong>, l’ordre dans lequel nous choisissons d’accéder aux éléments des matrices peut avoir <strong>un impact important sur les performances</strong>. Les caches fonctionnent mieux (i.e. un meilleur taux de succès) lorsque les accès à la mémoire exposent une localité spatiale et temporelle, permettant la réutilisation des blocs de données déjà contenus dans le cache. L’optimisation des schémas d’accès à la mémoire dans un programme est essentielle pour obtenir de bonnes performances.</p>

<p>Ouvrez le fichier en langage C <code class="language-plaintext highlighter-rouge">matrixMultiply.c</code> dans l’éditeur de votre choix et examinez son contenu. Vous remarquerez que le fichier contient six implémentations (l’une d’elles est illustrée ci-dessus) de multiplication de matrices en utilisant des ordres différents des trois boucles imbriquées.</p>

<p><strong>Tâche :</strong> Déduisez les pas utilisés dans chaque ensemble de boucles imbriquées des cinq autres implémentations.</p>

<p>Compilez et exécutez le fichier <code class="language-plaintext highlighter-rouge">matrixMultiply.c</code> avec la commande suivante, puis répondez aux questions ci-dessous.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make ex2
</code></pre></div></div>

<p>Notez que la commande de compilation dans le Makefile utilise l’indicateur ‘-O3’. Ce paramètre permet d’activer toutes les optimisations de performance possible du compilateur. La commande ci-dessous exécutera quelques multiplications de matrice selon les six implémentations différentes dans le fichier, et affichera la vitesse à laquelle chaque implémentation a exécuté l’opération. L’unité « Gflops/s » signifie : « Giga-opérations en virgule flottante par seconde ». Plus le nombre est grand, plus le calcul est rapide !</p>

<ol>
  <li>
    <p>Quel(s) ordre(s) de boucles donne(nt) le meilleur résultat ? Pourquoi ?</p>
  </li>
  <li>
    <p>Quel(s) ordre(s) de boucles donne(nt) le pire résultat ? Pourquoi ?</p>
  </li>
  <li>
    <p>Comment la façon dont nous parcourons les matrices affecte-t-elle les performances ?</p>
  </li>
</ol>

<h1 id="exercice-3-transposition-de-matrice-par-bloc">Exercice 3: (Transposition de matrice par bloc)</h1>

<h2 id="transposition-matricielle">Transposition matricielle</h2>

<p>Nous souhaitons permuter les lignes et les colonnes d’une matrice (voir figure ci-dessous). Cette opération est appelée <em>transposition de matrice</em> et une implémentation efficace peut être très utile, particulièrement quand on effectue des opérations assez compliquées en algèbre linéaire. La transposée de la matrice A est souvent désignée par A<sup><em>T</em></sup>.</p>

<p><img src="/l2cod/static_files/images/matrix_transpose.png" alt="Transposition" class="aligncenter" width="50%" height="50%" /></p>

<h2 id="le--cache-blocking-">Le « cache-blocking »</h2>

<p>Dans l’exercice précédent sur les multiplications de matrices, nous parcourons (avec des pas différents) toutes les valeurs des matrices A et B pour calculer une valeur de la matrice C. Ainsi, nous accédons constamment à de nouvelles valeurs de la mémoire et obtenons très peu de localité temporelle et / ou spatiale des accès mémoire !</p>

<p>Nous pouvons améliorer la quantité de réutilisation des données dans les caches en implémentant une technique appelée « cache-blocking ». Plus formellement, Le « cache-blocking » est une technique qui consiste à ré-écrire une opération sur les tableaux de sorte à forcer la réutilisation des données présentes dans le cache. Elle doit donc prendre en compte la taille du cache comme argument. Dans le cas de la transposition matricielle, on envisage d’effectuer la transposition un bloc à la fois.</p>

<p><img src="/l2cod/static_files/images/block_matrix_transpose.png" alt="BlocTransposition" class="aligncenter" width="50%" height="50%" /></p>

<p>Dans l’image ci-dessus, nous transposons chaque sous-matrice \(A_{ij}\) de la matrice \(A\) dans son <strong>emplacement final</strong> dans la matrice de sortie, une sous-matrice à la fois. Nous pouvons vérifier que la transposition de chaque sous-matrice individuelle est équivalent à la transposition de la matrice entière.</p>

<p>Puisque la transposition de la matrice entière est effectuée une sous-matrice à la fois, cela permet de consolider en cache les accès mémoire à ce petit morceau de données lors de la transposition de cette sous-matrice particulière; ce qui augmente le degré de localité temporelle (et spatiale) que nous exposons et améliore ainsi les performances.</p>

<p>Dans cet exercice, vous allez compléter une implémentation pour la transposition de matrice et analyser ses performances.
En particulier, votre tâche consiste à implémenter la technique du « cache-blocking » dans la fonction <code class="language-plaintext highlighter-rouge">transpose_blocking()</code> dans le fichier <code class="language-plaintext highlighter-rouge">transpose.c</code>. <strong>Vous ne devez PAS supposer que la largeur de la matrice (<code class="language-plaintext highlighter-rouge">n</code>) est un multiple de la taille du bloc <code class="language-plaintext highlighter-rouge">blocksize</code></strong>. Après avoir implémenté la fonction <code class="language-plaintext highlighter-rouge">transpose_blocking()</code>, vous pouvez compiler et exécuter votre code en tapant :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make ex3
<span class="nv">$ </span>./transpose n blocksize
</code></pre></div></div>

<p>où <code class="language-plaintext highlighter-rouge">n</code> est la largeur de la matrice et <code class="language-plaintext highlighter-rouge">blocksize</code> est la taille du bloc. Par exemple, <code class="language-plaintext highlighter-rouge">n</code> = 10000 et <code class="language-plaintext highlighter-rouge">blocksize</code> = 33.</p>

<p>Si votre implémentation de <code class="language-plaintext highlighter-rouge">transpose_blocking()</code> est correcte, la méthode de découpage en blocs devrait montrer une amélioration substantielle des performances par rapport à la version ‘naïve’.</p>

<p><strong>Conseils :</strong> (si vous ne savez pas par où commencer !)</p>

<p>Commencez par examiner la fonction <code class="language-plaintext highlighter-rouge">transpose_naive()</code> incluse dans le fichier. Notez que l’indice <code class="language-plaintext highlighter-rouge">y</code> parcourt verticalement TOUTE la matrice <code class="language-plaintext highlighter-rouge">src</code> dans une itération de la boucle externe avant de se remettre à <code class="language-plaintext highlighter-rouge">0</code>. Une autre façon de dire cela est que l’indice <code class="language-plaintext highlighter-rouge">x</code> est mis à jour seulement après que l’indice <code class="language-plaintext highlighter-rouge">y</code> ait parcouru toute la plage d’indices <code class="language-plaintext highlighter-rouge">[0 .. n-1]</code>. C’est le comportement que nous voudrions changer, on aimerait éviter de parcourir tous les indices du tableau.</p>

<p>En bref : remplissez <code class="language-plaintext highlighter-rouge">dst</code> avec un bloc carré à la fois, où chaque bloc est de dimension <code class="language-plaintext highlighter-rouge">blocsize</code> par <code class="language-plaintext highlighter-rouge">blocsize</code>.</p>

<p>Au lieu de mettre à jour <code class="language-plaintext highlighter-rouge">x</code> uniquement lorsque <code class="language-plaintext highlighter-rouge">y</code> ait parcouru tous les indices <code class="language-plaintext highlighter-rouge">0</code> à <code class="language-plaintext highlighter-rouge">n-1</code>, vous voudriez passer à la ligne suivante de <code class="language-plaintext highlighter-rouge">dst</code> après avoir parcouru la largeur (axe horizontal) d’un seul bloc. De même, vous voudriez parcourir seulement la hauteur d’un bloc (axe vertical) avant de passer au bloc suivant. Quelle est la taille d’un bloc ? Elle est donnée par le paramètre <code class="language-plaintext highlighter-rouge">blocksize</code> !</p>

<p><strong>Indication :</strong> Une solution simple nécessite quatre boucles <code class="language-plaintext highlighter-rouge">for</code>.</p>

<p>Enfin, comme la largeur de la matrice <code class="language-plaintext highlighter-rouge">n</code> n’est pas nécessairement un multiple de la taille de bloc <code class="language-plaintext highlighter-rouge">blocksize</code>, la colonne et ligne finales de blocs seront tronquées (voir les blocs \(A_{3\_}\) et \(A_{\_3}\) dans la figure ci-dessous). Pour gérer cette situation, vous pouvez faire l’exercice en supposant au début que <code class="language-plaintext highlighter-rouge">n</code> est un multiple de <code class="language-plaintext highlighter-rouge">blocksize</code>, puis ajouter une condition quelque part dans le code pour ne rien faire lorsque vos index dépassent les limites de la matrice.</p>

<p><img src="/l2cod/static_files/images/size_mismatch_matrix_transpose.png" alt="CutBlocTransposition" class="aligncenter" width="50%" height="50%" /></p>

<p>Une fois que votre implémentation fonctionne corrèctement, l’étape suivante est d’effectuer une analyse des performances du programme.</p>

<h2 id="modifier-les-dimensions-des-matrices">Modifier les dimensions des matrices</h2>

<p>Exécutez votre code plusieurs fois avec une valeur de <code class="language-plaintext highlighter-rouge">blocksize</code> fixée à 20 et les valeurs 100, 1000, 2000, 5000 et 10000 pour <code class="language-plaintext highlighter-rouge">n</code>.</p>

<ul>
  <li>
    <p>À quel moment la version de transposition par « cache-blocking » devient plus rapide que la version ‘naïve’ ?</p>
  </li>
  <li>
    <p>Pourquoi la version en « cache-blocking » nécessite-t-elle que la matrice ait une certaine taille avant de surpasser les performances de la version ‘naïve’ ?</p>
  </li>
</ul>

<h2 id="modifier-la-taille-de-bloc">Modifier la taille de bloc</h2>

<p>Fixez <code class="language-plaintext highlighter-rouge">n</code> à 10000 et exécutez votre code avec une taille de bloc <code class="language-plaintext highlighter-rouge">blocksize</code> égale à 50, 100, 500, 1000, 5000.</p>

<ul>
  <li>Comment les performances changent-elles lorsque la taille du bloc augmente ? Pourquoi ?</li>
</ul>

<p><strong>Note finale :</strong> Dans les deux derniers exercices, les paramètres de cache de notre machine nous sont inconnus. Nous nous sommes simplement assurés que notre code expose un degré plus élevé de localité, et cela <!--, comme par magie,--> a amélioré considérablement les performances ! Cela indique que les caches, quels que soient leurs caractéristiques spécifiques, fonctionneront toujours mieux sur du code qui présente un bon niveau de localité (spatiale et/ou temporelle).</p>

<!--
Les caches exploitent la localité spatiale et temporelle des accès mémoire. Bien que le code présente naturellement ces deux choses, nous pouvons généralement le modifier pour qu'il présente PLUS de ces deux choses, améliorant ainsi notre taux de réussite du cache et augmentant ainsi notre vitesse d'exécution.
-->
